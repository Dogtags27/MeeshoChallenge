{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84705,"databundleVersionId":9755748,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Read the Parquet file\ndf = pd.read_parquet('/kaggle/input/visual-taxonomy/category_attributes.parquet', engine='pyarrow')  # or engine='fastparquet'\n\n# Display the DataFrame\nprint(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Set Pandas options to display more data\npd.set_option('display.max_columns', None)  # Display all columns\npd.set_option('display.max_rows', None)     # Display all rows\npd.set_option('display.max_colwidth', None)  # Display full content in each column\n\n# Assuming your DataFrame is already loaded\nprint(df)  # or df.head() if you just want the top few rows","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Correcting just Kurtis data**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors as mcolors\n\n# Load the data\ndata = pd.read_csv('/kaggle/input/visual-taxonomy/train.csv')\nprint(\"Loaded csv file.\")\nprint(data.head())\n\n# Specify the target category\ntarget_category = \"Kurtis\"\n\n# Filter data to include only the specified category\nfiltered_data = data[data['Category'] == target_category]\n\n# Function to generate a unique color map based on the number of categories in a column\ndef generate_colors(n):\n    color_list = list(mcolors.TABLEAU_COLORS)  # Use Tableau colors for variety\n    if n <= len(color_list):\n        return color_list[:n]\n    else:\n        return plt.cm.get_cmap('hsv', n)(range(n))  # Generate unique colors if categories exceed standard colors\n\n# Loop through each column in the filtered data to generate pie charts\ncolumns_to_plot = [column for column in filtered_data.columns if column not in ['id', 'Category','len']]\nnum_attributes = len(columns_to_plot)  # Calculate number of attributes to plot\nnum_rows = (num_attributes + 1) // 2  # Calculate number of rows needed (2 columns)\n\n# Create a figure with a 2-column grid\nfig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(12, 5 * num_rows))\naxes = axes.flatten()  # Flatten the axes array for easy iteration\n\n# Loop through each column to generate pie charts\nfor i, column in enumerate(columns_to_plot):\n    # Calculate value counts for the column, including missing values\n    value_counts = filtered_data[column].value_counts(dropna=False)\n    if value_counts.isnull().any():\n        value_counts.index = value_counts.index.fillna('Missing')  # Label missing values as 'Missing'\n\n    # Generate a unique color map for each pie chart\n    colors = generate_colors(len(value_counts))\n\n    # Plot pie chart on the corresponding axes\n    axes[i].pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=140, colors=colors)\n    axes[i].set_title(f\"Distribution of {column} for {target_category}\")\n\n# Hide any empty subplots\nfor j in range(i + 1, len(axes)):\n    axes[j].axis('off')\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport os\n\n# Load and preprocess the data\ntrain_csv_path = '/kaggle/input/visual-taxonomy/train.csv'\ntrain_img_dir = '/kaggle/input/visual-taxonomy/train_images/'\n\n# Load the labels from train.csv\ndata = pd.read_csv(train_csv_path)\n\n# Filter data for \"Men Tshirts\" category and select the first 8 columns for attributes\ntarget_category = \"Kurtis\"\ndf = data[data['Category'] == target_category]\n\ndf['image_path'] = df['id'].apply(lambda x: os.path.join(train_img_dir, f\"{x:06d}.jpg\"))\ndf = df.drop(['Category','len','attr_10'], axis=1)\ndf.rename(columns={'attr_1': 'color', 'attr_2': 'fit_shape','attr_3': 'length','attr_4': 'occasion','attr_5': 'ornamentation','attr_6': 'pattern','attr_7': 'print_or_pattern_type','attr_8': 'sleeve_length','attr_9': 'sleeve_styling'}, inplace=True)\n# df = df.fillna('dummy_value')\n# df = df.dropna()\nprint(\"Done\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values = df.isnull().sum()\nprint(\"Missing values per column:\\n\", missing_values)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**50% of data is missing. So let us try to impute certain values there using models**","metadata":{}},{"cell_type":"code","source":"train_df=df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to load and preprocess image\ndef preprocess_image(image_path):\n    img = load_img(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n    img_array = img_to_array(img)\n    img_array = preprocess_input(img_array)\n    return img_array\n\n# Example function to create a CNN-based model for imputation\ndef create_imputer_model(output_classes):\n    base_model = tf.keras.applications.ResNet50(\n        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n        include_top=False,\n        weights='imagenet'\n    )\n    base_model.trainable = False  # Freeze backbone for initial training\n    \n    model = tf.keras.Sequential([\n        base_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(output_classes, activation='softmax')\n    ])\n    \n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport numpy as np\n\n# Dictionary to store mappings for each categorical column\nlabel_mappings = {}\ncategorical_columns = ['color', 'fit_shape', 'length', 'occasion', 'ornamentation', 'pattern', 'print_or_pattern_type', 'sleeve_length', 'sleeve_styling']  \n\n# Loop over each categorical column, encode, and store mapping\nfor col in categorical_columns:\n    le = LabelEncoder()\n    \n    # Fit and transform only non-missing values\n    non_missing = train_df[col].dropna()\n    train_df.loc[train_df[col].notna(), col] = le.fit_transform(non_missing)\n    \n    # Store the mapping of classes to integer labels\n    label_mappings[col] = dict(enumerate(le.classes_))\n    \n    # Ensure missing values are restored as NaN in the DataFrame\n    train_df[col] = train_df[col].astype(float)  # Ensure NaN compatibility\n    train_df.loc[train_df[col].isnull(), col] = np.nan\n    \nprint(\"Encoded DataFrame:\")\nprint(train_df.head())\nprint(\"\\nLabel Mappings:\")\nprint(label_mappings)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nimport numpy as np\nfrom tensorflow.keras.backend import clear_session\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nimport numpy as np\n\n# Constants for image dimensions and batch size\nIMG_HEIGHT, IMG_WIDTH = 224, 224\nBATCH_SIZE = 32\n\n# For each attribute, filter data, train model, and impute missing values\nfor attribute in ['color', 'fit_shape', 'length', 'occasion', 'ornamentation', 'pattern', 'print_or_pattern_type', 'sleeve_length', 'sleeve_styling']:\n    # Filter data for attribute (only rows where this attribute is not missing)\n    subset = train_df.dropna(subset=[attribute])\n    \n    # Limit the number of rows to 10,000 if it exceeds that count\n    if len(subset) > 10000:\n        subset = subset.sample(n=10000, random_state=42)\n        print(\"triggered\")\n    \n    # Load and preprocess images\n    X = np.array([preprocess_image(img_path) for img_path in subset['image_path']])\n    y = subset[attribute].values\n    \n    # Train-test split\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    # Initialize and train the CNN-based model\n    model = create_imputer_model(output_classes=len(label_mappings[attribute]))\n    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=BATCH_SIZE)\n    \n    \n    \n    # Impute missing values\n    missing_subset = train_df[train_df[attribute].isnull()]\n    batch_size = len(missing_subset)//20  # Adjust batch size according to available memory\n\n    if not missing_subset.empty:\n        print(\"Starting prediction for missing values...\")\n\n        # Initialize an empty list to collect predictions\n        y_missing_pred = []\n\n        # Process X_missing in batches\n        for start in range(0, len(missing_subset), batch_size):\n            end = min(start + batch_size, len(missing_subset))\n\n            print(f\"Processing batch from {start} to {end}\")\n\n            # Preprocess the images in the current batch\n            X_batch = np.array([preprocess_image(img_path) for img_path in missing_subset['image_path'][start:end]])\n\n            # Predict for the current batch\n            y_batch_pred = model.predict(X_batch).argmax(axis=1)\n\n            # Append the batch predictions to the main list\n            y_missing_pred.extend(y_batch_pred)\n\n    # Convert to numpy array if needed, then update the DataFrame\n    y_missing_pred = np.array(y_missing_pred)\n\n    print(f\"Predicted: {attribute}\")\n    train_df.loc[train_df[attribute].isnull(), attribute] = y_missing_pred\n        \n# Now train the final model on the fully imputed dataset with images and attributes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values = train_df.isnull().sum()\nprint(\"Missing values per column:\\n\", missing_values)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_mappings","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert float columns to int before mapping\nfor column, mapping in label_mappings.items():\n    train_df[column] = train_df[column].astype(int).map(mapping)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Checking model accuracy after imputation**","metadata":{}},{"cell_type":"code","source":"df = train_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Dictionary to store mappings for each categorical column\nlabel_mappings = {}\ncategorical_columns = ['color', 'fit_shape', 'length', 'occasion', 'ornamentation', 'pattern', 'print_or_pattern_type', 'sleeve_length', 'sleeve_styling']\n# Loop over each categorical column, encode, and store mapping\nfor col in categorical_columns:\n    le = LabelEncoder()\n    # Fit and transform the column to integer codes\n    df[col] = le.fit_transform(df[col])\n    \n    # Store the mapping of classes to integer labels\n    label_mappings[col] = dict(enumerate(le.classes_))\n\nprint(\"Encoded DataFrame:\")\nprint(df.head())\nprint(\"\\nLabel Mappings:\")\nprint(label_mappings)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\n# Split the data for training and validation\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n\n# Define image parameters\nIMG_HEIGHT, IMG_WIDTH = 224, 224  # Standard image size for CNN models\nBATCH_SIZE = 32\n\n# Data generator for real-time data augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,            # Normalize pixel values\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Train and validation data generators\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=train_img_dir,\n    x_col='image_path',\n    y_col=['color', 'fit_shape', 'length', 'occasion', 'ornamentation','pattern', 'print_or_pattern_type', 'sleeve_length', 'sleeve_styling'],\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='multi_output'\n)\n\nval_generator = train_datagen.flow_from_dataframe(\n    dataframe=val_df,\n    directory=train_img_dir,\n    x_col='image_path',\n    y_col=['color', 'fit_shape', 'length', 'occasion', 'ornamentation', 'pattern', 'print_or_pattern_type', 'sleeve_length', 'sleeve_styling'],\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='multi_output'\n)\n\n# Model Architecture\ndef build_model():\n    # Shared Backbone\n    base_model = tf.keras.applications.ResNet50(\n        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n        include_top=False,\n        weights='imagenet'\n    )\n    base_model.trainable = False  # Freeze the backbone initially\n\n    # Global feature extractor\n    x = layers.GlobalAveragePooling2D()(base_model.output)\n\n    # Attribute-specific heads\n    color_head = layers.Dense(128, activation='relu')(x)\n    color_head = layers.Dense(num_classes['color'], activation='softmax', name='color')(color_head)\n\n    fit_shape_head = layers.Dense(128, activation='relu')(x)\n    fit_shape_head = layers.Dense(num_classes['fit_shape'], activation='softmax', name='fit_shape')(fit_shape_head)\n\n    length_head = layers.Dense(128, activation='relu')(x)\n    length_head = layers.Dense(num_classes['length'], activation='softmax', name='length')(length_head)\n\n    occasion_head = layers.Dense(128, activation='relu')(x)\n    occasion_head = layers.Dense(num_classes['occasion'], activation='softmax', name='occasion')(occasion_head)\n\n    ornamentation_head = layers.Dense(128, activation='relu')(x)\n    ornamentation_head = layers.Dense(num_classes['ornamentation'], activation='softmax', name='ornamentation')(ornamentation_head)\n\n    pattern_head = layers.Dense(128, activation='relu')(x)\n    pattern_head = layers.Dense(num_classes['pattern'], activation='softmax', name='pattern')(pattern_head)\n\n    print_type_head = layers.Dense(128, activation='relu')(x)\n    print_type_head = layers.Dense(num_classes['print_or_pattern_type'], activation='softmax', name='print_or_pattern_type')(print_type_head)\n\n    sleeve_length_head = layers.Dense(128, activation='relu')(x)\n    sleeve_length_head = layers.Dense(num_classes['sleeve_length'], activation='softmax', name='sleeve_length')(sleeve_length_head)\n\n    sleeve_styling_head = layers.Dense(128, activation='relu')(x)\n    sleeve_styling_head = layers.Dense(num_classes['sleeve_styling'], activation='softmax', name='sleeve_styling')(sleeve_styling_head)\n\n    # Define the model\n    model = models.Model(inputs=base_model.input, outputs=[\n        color_head, fit_shape_head, length_head, occasion_head, ornamentation_head, \n        pattern_head, print_type_head, sleeve_length_head, sleeve_styling_head\n    ])\n    \n    return model\n\n# Number of classes for each attribute\nnum_classes = {\n    'color': df['color'].nunique(),\n    'fit_shape': df['fit_shape'].nunique(),\n    'length': df['length'].nunique(),\n    'occasion': df['occasion'].nunique(),\n    'ornamentation': df['ornamentation'].nunique(),\n    'pattern': df['pattern'].nunique(),\n    'print_or_pattern_type': df['print_or_pattern_type'].nunique(),\n    'sleeve_length': df['sleeve_length'].nunique(),\n    'sleeve_styling': df['sleeve_styling'].nunique()\n}\n\n# Instantiate and compile the model\nmodel = build_model()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\ndef create_dataset(dataframe, batch_size):\n    def generator():\n        for _, row in dataframe.iterrows():\n            # Load and preprocess the image\n            img = tf.io.read_file(row['image_path'])\n            img = tf.image.decode_jpeg(img, channels=3)\n            img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n            img = img / 255.0  # Normalize to [0,1]\n\n            # Labels as a tuple of individual attributes for the Saree dataset\n            labels = (\n                row['color'],\n                row['fit_shape'],\n                row['length'],\n                row['occasion'],\n                row['ornamentation'],\n                row['pattern'],\n                row['print_or_pattern_type'],\n                row['sleeve_length'],\n                row['sleeve_styling']\n            )\n            yield img, labels\n\n    # Set the output signature for TensorFlow to understand the data types and shapes\n    output_signature = (\n        tf.TensorSpec(shape=(IMG_HEIGHT, IMG_WIDTH, 3), dtype=tf.float32),  # Image shape and dtype\n        (\n            tf.TensorSpec(shape=(), dtype=tf.int32),  # color\n            tf.TensorSpec(shape=(), dtype=tf.int32),  # neck\n            tf.TensorSpec(shape=(), dtype=tf.int32),  # pattern\n            tf.TensorSpec(shape=(), dtype=tf.int32),  # print_or_pattern_type\n            tf.TensorSpec(shape=(), dtype=tf.int32),  # sleeve_length\n            tf.TensorSpec(shape=(), dtype=tf.int32),  # color\n            tf.TensorSpec(shape=(), dtype=tf.int32),  # neck\n            tf.TensorSpec(shape=(), dtype=tf.int32),  # pattern\n            tf.TensorSpec(shape=(), dtype=tf.int32),  # print_or_pattern_type\n        )\n    )\n\n    # Create the dataset from the generator\n    dataset = tf.data.Dataset.from_generator(\n        generator,\n        output_signature=output_signature\n    )\n    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n# Create train and validation datasets\ntrain_dataset = create_dataset(train_df, BATCH_SIZE)\nval_dataset = create_dataset(val_df, BATCH_SIZE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Let us predict the images in test.csv**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\n\n# Load the test.csv and filter for the target category\ntest_csv_path = '/kaggle/input/visual-taxonomy/test.csv'\ntest_img_dir = '/kaggle/input/visual-taxonomy/test_images/'\n\n# Load and filter the data\ntest_data = pd.read_csv(test_csv_path)\ntest_data = test_data[test_data['Category'] == target_category]\n\n# Create image paths\ntest_data['image_path'] = test_data['id'].apply(lambda x: os.path.join(test_img_dir, f\"{x:06d}.jpg\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to create a dataset from test images\ndef create_test_dataset(dataframe, batch_size):\n    def generator():\n        for _, row in dataframe.iterrows():\n            # Load and preprocess the image\n            img = tf.io.read_file(row['image_path'])\n            img = tf.image.decode_jpeg(img, channels=3)\n            img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n            img = img / 255.0  # Normalize to [0,1]\n            yield img\n\n    output_signature = tf.TensorSpec(shape=(IMG_HEIGHT, IMG_WIDTH, 3), dtype=tf.float32)\n    \n    # Create the dataset\n    dataset = tf.data.Dataset.from_generator(\n        generator,\n        output_signature=output_signature\n    )\n    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize submission DataFrame with columns 'id', 'Category', 'len', and the attribute columns\nsubmission = pd.DataFrame(columns=['id', 'Category', 'len','color', 'fit_shape', 'length', 'occasion','ornamentation', 'pattern', 'print_or_pattern_type', 'sleeve_length', 'sleeve_styling'])\n\n# Set 'Category' and 'len' columns\nsubmission['Category'] = target_category\nsubmission['len'] = 9\n\n# Loop over each image in the test data\nfor index, row in test_data.iterrows():\n    # Load and preprocess the image\n    img_path = os.path.join(test_img_dir, f\"{row['id']:06d}.jpg\")\n    img = tf.io.read_file(img_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n    img = img / 255.0  # Normalize\n    img_batch = tf.expand_dims(img, 0)  # Add batch dimension\n\n    # Predict using the model\n    predicted_outputs = model.predict(img_batch,verbose=0)\n\n    # Decode predictions using label mappings\n    predicted_attributes = []\n    for i, col in enumerate(['color', 'fit_shape', 'length', 'occasion','ornamentation', 'pattern', 'print_or_pattern_type', 'sleeve_length', 'sleeve_styling']):\n        predicted_label_idx = np.argmax(predicted_outputs[i], axis=1)[0]\n        predicted_label = label_mappings[col][predicted_label_idx]\n        predicted_attributes.append(predicted_label)\n\n    # Append the results to the submission DataFrame\n    submission = pd.concat([submission, pd.DataFrame([[row['id'], target_category, 9] + predicted_attributes],\n                                                     columns=submission.columns)], ignore_index=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Rename the columns ['blouse_pattern', 'border', 'border_width', 'color', 'occasion', \n           # 'ornamentation', 'pallu_details', 'pattern', 'print_or_pattern_type', 'transparency']\nsubmission.rename(columns={\n    'color': 'attr_1', \n    'fit_shape': 'attr_2', \n    'length': 'attr_3', \n    'occasion': 'attr_4', \n    'ornamentation': 'attr_5',\n    'pattern': 'attr_6',\n    'print_or_pattern_type': 'attr_7',\n    'sleeve_length': 'attr_8',\n    'sleeve_styling': 'attr_9'\n}, inplace=True)\n\n# Add columns attr_6 to attr_10 with \"dummy_value\"\nfor i in range(10, 11):\n    submission[f'attr_{i}'] = \"dummy_value\"\n\n# Save the modified DataFrame to CSV\noutput_path = \"/kaggle/working/submissionKurtisFinal.csv\"\nsubmission.to_csv(output_path, index=False)\n\nprint(f\"File saved successfully at {output_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = train_dataset.repeat()\nval_dataset = val_dataset.repeat()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Phase 1: Unfreeze the backbone and all layers\nfor layer in model.layers:\n    layer.trainable = True\n\n# Phase 1: Unfreeze the backbone and all layers\nfor layer in model.layers:\n    layer.trainable = True\n\n# Compile the model with a lower learning rate for fine-tuning\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=0.0001),\n    loss={\n        'color': 'sparse_categorical_crossentropy',\n        'fit_shape': 'sparse_categorical_crossentropy',\n        'length': 'sparse_categorical_crossentropy',\n        'occasion': 'sparse_categorical_crossentropy',\n        'ornamentation': 'sparse_categorical_crossentropy',\n        'pattern': 'sparse_categorical_crossentropy',\n        'print_or_pattern_type': 'sparse_categorical_crossentropy',\n        'sleeve_length': 'sparse_categorical_crossentropy',\n        'sleeve_styling': 'sparse_categorical_crossentropy'\n    },\n    metrics={\n        'color': ['accuracy'],\n        'fit_shape': ['accuracy'],\n        'length': ['accuracy'],\n        'occasion': ['accuracy'],\n        'ornamentation': ['accuracy'],\n        'pattern': ['accuracy'],\n        'print_or_pattern_type': ['accuracy'],\n        'sleeve_length': ['accuracy'],\n        'sleeve_styling': ['accuracy']\n    }\n)\n\ninitial_epochs = 10\n\nhistory_phase1 = model.fit(\n    train_dataset,\n    epochs=initial_epochs,\n    steps_per_epoch=len(train_df) // BATCH_SIZE,\n    validation_data=val_dataset,\n    validation_steps=len(val_df) // BATCH_SIZE,\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Define the names for each output\noutput_names = ['color', 'fit_shape', 'length', 'occasion', 'ornamentation', 'pattern', 'print_or_pattern_type', 'sleeve_length','sleeve_styling']\n\n# Create a plot for each output\nfor output_name in output_names:\n    plt.figure(figsize=(10, 5))\n    \n    # Plot training accuracy\n    plt.plot(history_phase1.history[f'{output_name}_accuracy'], label='Training Accuracy')\n    \n    # Plot validation accuracy\n    plt.plot(history_phase1.history[f'val_{output_name}_accuracy'], label='Validation Accuracy')\n    \n    # Set plot title and labels\n    plt.title(f'{output_name.capitalize()} Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    # Show the plot\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}